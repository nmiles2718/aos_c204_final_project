{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1228925a",
   "metadata": {},
   "source": [
    "# Train/Validation/Test Splits\n",
    "\n",
    "This notebooks is used to generate the train, validation, and test splits from the full dataset.\n",
    "\n",
    "The key here is to ensure that all intervals generated for each dataset are distinct and contain no overlap with intervals in the other datasets. This ensures we are not at risk for data leakage when training and testing our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201bb6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from collections import defaultdict, Counter\n",
    "import datetime as dt\n",
    "import glob \n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "np.random.seed(12345)\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b402ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../utils/sta_dataset_labels.txt', header=0, parse_dates=['start_time', 'stop_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea77151d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.868661\n",
       "1    0.131339\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8967cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "icmes = df[df.label.eq(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dacc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.15\n",
    "nval = round(validation_size * icmes.shape[0])\n",
    "train_size = 0.70\n",
    "ntrain = round(train_size * icmes.shape[0])\n",
    "test_size = 0.1\n",
    "ntest = round(test_size * icmes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "053e0ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([nval, ntrain, ntest]) == icmes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78ba41a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([ntrain, ntest, nval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caae6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interval_span(\n",
    "    ax, \n",
    "    df, \n",
    "    c='r',\n",
    "    hatch='*', \n",
    "    label='',\n",
    "    \n",
    "):\n",
    "    j = 0\n",
    "    for i, row in df.iterrows():\n",
    "        if j == 0:\n",
    "            ax.axvspan(row['start_time'], row['stop_time'], facecolor=c, alpha=0.3, label=label, hatch=hatch)\n",
    "        else:\n",
    "            ax.axvspan(row['start_time'], row['stop_time'], facecolor=c, alpha=0.3, hatch=hatch)\n",
    "        j+=1\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_train_test_val_intervals(\n",
    "    val_df, \n",
    "    test_df, \n",
    "    train_df, \n",
    "    xlim=(dt.datetime(2009,1,1), dt.datetime(2010,1, 1))\n",
    "):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 3))\n",
    "    plot_interval_span(ax, val_df, c='r', label='val', hatch=None)\n",
    "    plot_interval_span(ax, test_df, c='b', label='test', hatch=None)\n",
    "    plot_interval_span(ax, train_df, c='g', label='train', hatch=None)\n",
    "    ax.tick_params(which='both', axis='y', labelleft=False, left=False)\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        mdates.ConciseDateFormatter(\n",
    "            locator=mdates.MonthLocator(interval=2),\n",
    "            formats=['%Y', '%b', '%d', '%H:%M', '%H:%M', '%S.%f'],\n",
    "            offset_formats=[\n",
    "                '%Y',\n",
    "                '%b',\n",
    "                '%b %d, %Y',\n",
    "                '%b %d, %Y',\n",
    "                '%b %d, %Y',\n",
    "                '%b %d, %Y'\n",
    "            ],\n",
    "            zero_formats=['', '%Y', '%b', '%b-%d', '%H:%M', '%H:%M'],\n",
    "            show_offset=False\n",
    "        )\n",
    "    )\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.01, 0.9), edgecolor='k')\n",
    "    ax.set_xlim(xlim)\n",
    "    fig.savefig('interval_check.jpg', format='jpg', dpi=250, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c61c996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_samples(positive_class, df, nsamples, used_intervals=None, for_train=False):\n",
    "    dout = defaultdict(list)\n",
    "    if used_intervals is not None:\n",
    "        intervals_to_exclude = list(\n",
    "            zip(used_intervals['start_time'], used_intervals['stop_time'])\n",
    "        )\n",
    "    else:\n",
    "        intervals_to_exclude=[]\n",
    "\n",
    "    while len(dout['fname']) < nsamples:\n",
    "\n",
    "        pos_sample = positive_class.sample(1)\n",
    "        if intervals_to_exclude is not None:\n",
    "            distinct = check_used_intervals(intervals_to_exclude, pos_sample)\n",
    "        else:\n",
    "            distinct = True\n",
    "        if not distinct:\n",
    "            positive_class = positive_class.drop(index=pos_sample.index)\n",
    "\n",
    "            continue\n",
    "        # Get this sample and the following one from the full df\n",
    "        pos_cut = df.loc[pos_sample.index[0]: pos_sample.index[0]+1]\n",
    "\n",
    "        try:\n",
    "            tdiff = (pos_cut['start_time'].iloc[1] - pos_cut['start_time'].iloc[0]) / np.timedelta64(1,'D')\n",
    "        except IndexError:\n",
    "            continue\n",
    "        # if these samples are consecutive and both contain ICMEs continue\n",
    "        if tdiff  == 0.75 and all(pos_cut.label.eq(1)):\n",
    "            # consecutive interval and we are goo\n",
    "            for i, row in pos_cut.iterrows():\n",
    "                dout['fname'].append(row['fname'])\n",
    "                dout['label'].append(row['label'])\n",
    "                dout['start_time'].append(row['start_time'])\n",
    "                dout['stop_time'].append(row['stop_time'])\n",
    "                dout['index'].append(i)\n",
    "#                 intervals_to_exclude.append((row['start_time'], row['stop_time']))\n",
    "        else:\n",
    "            # try the current sample and the previous one\n",
    "            pos_cut = df.loc[pos_sample.index[0] - 1 : pos_sample.index[0]]\n",
    "            try:\n",
    "                tdiff = (pos_cut['start_time'].iloc[1] - pos_cut['start_time'].iloc[0]) / np.timedelta64(1,'D')\n",
    "            except IndexError:\n",
    "                continue\n",
    "#             print(tdiff, pos_cut.label.eq(1).iloc[0])\n",
    "            if tdiff == 0.75 and all(pos_cut.label.eq(1)):\n",
    "                # consecutive interval and we are good\n",
    "                for i, row in pos_cut.iterrows():\n",
    "                    dout['fname'].append(row['fname'])\n",
    "                    dout['label'].append(row['label'])\n",
    "                    dout['start_time'].append(row['start_time'])\n",
    "                    dout['stop_time'].append(row['stop_time'])\n",
    "                    dout['index'].append(i)\n",
    "            else:\n",
    "#                 print('Resampling...')\n",
    "                continue   \n",
    "\n",
    "    return dout\n",
    "\n",
    "def get_neg_samples(negative_class, df, nsamples, used_intervals):\n",
    "    dout = defaultdict(list)\n",
    "    intervals_to_exclude = list(zip(used_intervals['start_time'], used_intervals['stop_time']))\n",
    "    while len(dout['fname']) < nsamples:\n",
    "        neg_sample = negative_class.sample(1)\n",
    "        distinct = check_used_intervals(intervals_to_exclude, neg_sample)\n",
    "        if distinct:\n",
    "            for i, row in neg_sample.iterrows():\n",
    "                dout['fname'].append(row['fname'])\n",
    "                dout['label'].append(row['label'])\n",
    "                dout['start_time'].append(row['start_time'])\n",
    "                dout['stop_time'].append(row['stop_time'])\n",
    "                dout['index'].append(i)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return dout\n",
    "\n",
    "def check_used_intervals(intervals_to_exclude, sample):\n",
    "    distinct = []\n",
    "    for start, stop in intervals_to_exclude:\n",
    "        if sample['start_time'].iloc[0] == start and sample['stop_time'].iloc[0] == stop:\n",
    "            distinct.append(False)\n",
    "        elif sample['stop_time'].iloc[0] < start or sample['start_time'].iloc[0] > stop:\n",
    "            distinct.append(True)\n",
    "        else:\n",
    "            distinct.append(False)\n",
    "    return all(distinct)\n",
    "\n",
    "\n",
    "def trim_df(df, indices_to_drop, N):\n",
    "    print(f'Found {N} samples... trimming original df')\n",
    "    orig_shape = df.shape\n",
    "    df = df.drop(index=indices_to_drop)\n",
    "    new_shape = df.shape\n",
    "    print(f\"{orig_shape} --> {new_shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_test_train_split(df, ntest=20, ntrain=20, nval=20):\n",
    "    positive_class = df[df.label.eq(1)]\n",
    "    negative_class = df[df.label.eq(0)]\n",
    "    \n",
    "    train = defaultdict(list)\n",
    "    test = defaultdict(list)\n",
    "    pos_val = defaultdict(list)\n",
    "    neg_val = defaultdict(list)\n",
    "    used_intervals = defaultdict(list)\n",
    "    # build the validation set\n",
    "    print('Finding positive validation set')\n",
    "    pos_val = get_pos_samples(positive_class, df, nval)\n",
    "    used_intervals['start_time'] += pos_val['start_time']\n",
    "    used_intervals['stop_time'] += pos_val['stop_time']\n",
    "\n",
    "    print('Finding negative validation set')\n",
    "    neg_val = get_neg_samples(negative_class, df, nval, used_intervals)\n",
    "    used_intervals['start_time'] += neg_val['start_time']\n",
    "    used_intervals['stop_time'] += neg_val['stop_time']\n",
    "    \n",
    "    print('Finding positive test set')\n",
    "    pos_test = get_pos_samples(positive_class, df, ntest, used_intervals)\n",
    "    used_intervals['start_time'] += pos_test['start_time']\n",
    "    used_intervals['stop_time'] += pos_test['stop_time']\n",
    "    \n",
    "    print('Finding negative test set')\n",
    "    neg_test = get_neg_samples(negative_class, df, ntest, used_intervals)\n",
    "    used_intervals['start_time'] += neg_test['start_time']\n",
    "    used_intervals['stop_time'] += neg_test['stop_time']\n",
    "    \n",
    "    print('Finding positive train set')\n",
    "    pos_train = get_pos_samples(positive_class, df, ntrain, used_intervals, for_train=True)\n",
    "    used_intervals['start_time'] += pos_train['start_time']\n",
    "    used_intervals['stop_time'] += pos_train['stop_time']\n",
    "    \n",
    "    print('Finding negative train set')\n",
    "    neg_train = get_neg_samples(negative_class, df, ntrain, used_intervals)\n",
    "    used_intervals['start_time'] += neg_train['start_time']\n",
    "    used_intervals['stop_time'] += neg_train['stop_time']\n",
    "    \n",
    "\n",
    "    validation_set = defaultdict(list)\n",
    "    testing_set = defaultdict(list)\n",
    "    training_set = defaultdict(list)\n",
    "    \n",
    "    # Combine the positive and negative classes for each set into single\n",
    "    # dictionary and convert that to a dataframe\n",
    "    for key in pos_val.keys():\n",
    "        validation_set[key] += pos_val[key]\n",
    "        validation_set[key] += neg_val[key]\n",
    "\n",
    "    for key in pos_test.keys():\n",
    "        testing_set[key] += pos_test[key]\n",
    "        testing_set[key] += neg_test[key]\n",
    "        \n",
    "    for key in pos_train.keys():\n",
    "        training_set[key] += pos_train[key]\n",
    "        training_set[key] += neg_train[key]\n",
    "\n",
    "\n",
    "    val_df = pd.DataFrame(validation_set, index=validation_set['index'])\n",
    "    test_df = pd.DataFrame(testing_set, index=testing_set['index'])\n",
    "    train_df = pd.DataFrame(training_set, index=training_set['index'])\n",
    "    return val_df, test_df, train_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de4c3a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding positive validation set\n",
      "Finding negative validation set\n",
      "Finding positive test set\n",
      "Finding negative test set\n",
      "Finding positive train set\n",
      "Finding negative train set\n"
     ]
    }
   ],
   "source": [
    "val_df, test_df, train_df = generate_test_train_split(\n",
    "    df, nval=nval, ntrain=ntrain, ntest=ntest\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec0228",
   "metadata": {},
   "source": [
    "Check to make sure there is no overlap between the train/validation/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98cc169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = set(train_df['fname'])\n",
    "test_f = set(test_df['fname'])\n",
    "val_f = set(val_df['fname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e39df75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(train_f.intersection(test_f))\n",
    "print(train_f.intersection(val_f))\n",
    "print(val_f.intersection(test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71f9ff2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405ebe3ee7be4d798f1618e16355a963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plot_train_test_val_intervals(val_df, test_df, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c9ad724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ndmiles/miniconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for df in [val_df, test_df, train_df]:\n",
    "    df['fname_img'] = df.fname.str.replace('ts_interval','img_interval').str.replace('.txt','.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91abd164",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv('../data/sta_validation_set.txt', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('../data/sta_test_set.txt', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/sta_train_set.txt', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
